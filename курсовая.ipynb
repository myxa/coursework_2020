{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1курсовая.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ajOg2gx_PLZ6",
        "54onLBg5Iq0H",
        "tODvhBFiIu5k",
        "0JUfVsb5PT5I",
        "Pi4LkFu4ym26",
        "br2M7wS2SztJ",
        "TbZpghkeg4ZG",
        "FK-sb2KOI5pT"
      ],
      "toc_visible": true,
      "mount_file_id": "1X6uwh9GJ39XKy4DfSaaqX5_rRGZS9kS_",
      "authorship_tag": "ABX9TyO4prQANlCqhvXaaITQyR6d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myxa/coursework_2020/blob/master/%D0%BA%D1%83%D1%80%D1%81%D0%BE%D0%B2%D0%B0%D1%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5Ub_PrYRzPH"
      },
      "source": [
        "# Разговорный чат-бот"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdJwJFcZlvnH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMt-sR3ZaYji"
      },
      "source": [
        "Обучающий датасет состоит из личных сообщений из вк за почти 10 лет. Также были добавлены диалоги из фильмов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHM8qPndaB_6"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/колаб/курсовая/merged.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eSHp7-0Eiea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "6d67acc3-98a7-4aa9-c66d-7fb0718f421c"
      },
      "source": [
        "data.sample(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63416</th>\n",
              "      <td>это правда ?</td>\n",
              "      <td>нет .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18352</th>\n",
              "      <td>А шо ты вдруг вспомнил</td>\n",
              "      <td>та мне для анкеты нада указать када я учился в...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8533</th>\n",
              "      <td>нарисовал чо-нить ? ? ?</td>\n",
              "      <td>Та</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72253</th>\n",
              "      <td>а зачем мне перчатки ?</td>\n",
              "      <td>чтобы проголосовать .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36244</th>\n",
              "      <td>Из дк это</td>\n",
              "      <td>а</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80427</th>\n",
              "      <td>это было бы плохо .</td>\n",
              "      <td>он бы уже был великим рыцарем .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115545</th>\n",
              "      <td>и он исчезнет .</td>\n",
              "      <td>и снова вернется .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36588</th>\n",
              "      <td>поооч</td>\n",
              "      <td>Гуашь_(((((</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33590</th>\n",
              "      <td>ну да ладно</td>\n",
              "      <td>Ну да ладно</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119044</th>\n",
              "      <td>всё совершенно нормально \" . так , что йен нич...</td>\n",
              "      <td>почему бы тебе не заглядывать к нему время от ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  context                                              reply\n",
              "63416                                        это правда ?                                              нет .\n",
              "18352                              А шо ты вдруг вспомнил  та мне для анкеты нада указать када я учился в...\n",
              "8533                              нарисовал чо-нить ? ? ?                                                 Та\n",
              "72253                              а зачем мне перчатки ?                              чтобы проголосовать .\n",
              "36244                                           Из дк это                                                  а\n",
              "80427                                 это было бы плохо .                    он бы уже был великим рыцарем .\n",
              "115545                                    и он исчезнет .                                 и снова вернется .\n",
              "36588                                               поооч                                        Гуашь_(((((\n",
              "33590                                         ну да ладно                                        Ну да ладно\n",
              "119044  всё совершенно нормально \" . так , что йен нич...  почему бы тебе не заглядывать к нему время от ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqGemHcfa0T7"
      },
      "source": [
        "$X$ -- context (чье-то сообщение), таргет -- reply (мой ответ). В процессе отчистки сообщений от служебных символов пары контекст-ответ могли поменяться местами, но это не критично, я думаю."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajOg2gx_PLZ6"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3sGBgV_bevI"
      },
      "source": [
        "Попытка создать не нейросетевой алгоритм для решения этой задачи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaaiJ2D6qUhl"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "from sklearn.neighbors import BallTree\n",
        "from sklearn.base import BaseEstimator"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-dqFeEglI5V"
      },
      "source": [
        "Сначала получаем представления предложений как TF-IDF векторы  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPExwn-d1Ora"
      },
      "source": [
        "tf = TfidfVectorizer()\n",
        "bag = tf.fit(data['context'])\n",
        "transformed = bag.transform(data['context'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEjpYMXtlZO2"
      },
      "source": [
        "Далее используем SVD-разложение для уменьшения размерности"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv3ElE5R1vhQ"
      },
      "source": [
        "svd = TruncatedSVD(n_components=500)\n",
        "small = svd.fit(transformed)\n",
        "\n",
        "vecs = small.transform(transformed)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sCopaByliMU"
      },
      "source": [
        "Сам алгоритм устроен просто -- кластеризуем все векторы context и потом просто берем рандомный вектор из пяти ближайших и используем его как ответ модели. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtJOGWGh4UlP"
      },
      "source": [
        "def softmax(x):\n",
        "  return np.exp(x)/sum(np.exp(x))\n",
        "\n",
        "class NeighborSampler(BaseEstimator):\n",
        "  def __init__(self, k=5, temp=1.0):\n",
        "    self.k = k\n",
        "    self.temp = temp\n",
        "  def fit(self, X, y):\n",
        "    self.tree_ = BallTree(X)\n",
        "    self.y_ = np.array(y)\n",
        "    \n",
        "  def predict(self, X, random_state=42):\n",
        "    dist, ind = self.tree_.query(X, return_distance=True, k=self.k)\n",
        "\n",
        "    result = []\n",
        "    for d, i in zip(dist, ind):\n",
        "      p=softmax(d * self.temp)\n",
        "      result.append(np.random.choice(i))\n",
        "\n",
        "    return self.y_[result]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmKBS4nAp-NK"
      },
      "source": [
        "### Примеры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hR8ux8Pl-Kf"
      },
      "source": [
        "Обучаем модель на ответах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CPiv3Gb5u7c"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "sampler = NeighborSampler(k=5, temp=0.7)\n",
        "sampler.fit(vecs, data['reply'])\n",
        "pipe = make_pipeline(tf, svd, sampler)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxq1aLelidZZ"
      },
      "source": [
        "def inference():\n",
        "  \"\"\" просто говорилка \"\"\"\n",
        "  while True:\n",
        "    inp = input()\n",
        "    answer = pipe.predict([inp])[0]\n",
        "    print(answer)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVtZXuX4mGNE"
      },
      "source": [
        "Некоторые примеры, которые показались мне до смешного точными"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY7fZ7cg6hla",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "543a99e1-5288-43d1-a17b-3e9e95f36c84"
      },
      "source": [
        "pipe.predict(['приветик'])[0]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'здравствуй - здравствуй .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_Lb2N7V6nVW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "93809d61-6c77-4d6e-851c-2cf6e08ee513"
      },
      "source": [
        "pipe.predict(['что же делать?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['для начала сесть и начать уже говорить чертову правду .'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw54MKx36r9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe66973-4517-47b7-e69c-85c5dd844f12"
      },
      "source": [
        "pipe.predict(['как дела?'])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['все хорошо .'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHcqclBV6yeK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32769dbd-e037-4d4e-d542-4d207bc62690"
      },
      "source": [
        "pipe.predict(['пошли покушаем'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['быстрее !'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQZug7jc7Q7i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b98b3bd-aac4-42b8-8943-a3f34fb4f52c"
      },
      "source": [
        "pipe.predict(['я спать'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ну спать так спать'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dvoHoH17TJL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7845cda3-2c05-457b-d8bf-c01b70f5554a"
      },
      "source": [
        "pipe.predict(['ты где?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['На адмиралтейской'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fah-4sBt7WJb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca3490d3-101a-4600-a823-6c3eb296ab17"
      },
      "source": [
        "pipe.predict(['андрюха'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['А шо нитак'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2hKYapP7wzy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "527b543b-0d80-449b-bb69-d113a18daca8"
      },
      "source": [
        "pipe.predict(['ничо особенного'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['АВЗХАВЗАЗВЗХХ'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTlwSlKk9Mh-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0edda63d-0efa-49e9-a5c4-743964f24bff"
      },
      "source": [
        "pipe.predict(['ты Ленин'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ДААААААА'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7jNUUS7_2sy"
      },
      "source": [
        "# seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLSqPk2WACCx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "import spacy\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        " \n",
        "import torch.nn.functional as F\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKPt6mvipmhl"
      },
      "source": [
        "## Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVdnAaVCAOnp"
      },
      "source": [
        "seed = 43\n",
        "\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "movie = '/content/drive/My Drive/курсовая/movie.csv'\n",
        "merged = '/content/drive/My Drive/курсовая/merged.csv'\n",
        "my = '/content/drive/My Drive/курсовая/my.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbZpghkeg4ZG"
      },
      "source": [
        "### messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTLOTu_FqOuK"
      },
      "source": [
        "Здесь было решено разделить датасеты, потому что оба два за раз colab не вывозил"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDyyI8cbAUl7"
      },
      "source": [
        "context = Field(tokenize = 'spacy',\n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n",
        "\n",
        "reply = Field(tokenize = 'spacy',\n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEGwbF5M_8sc"
      },
      "source": [
        "dataset = TabularDataset(my, 'csv', \n",
        "                          [('context', context), (\"reply\", reply)], \n",
        "                          skip_header=True)\n",
        "\n",
        "train, test = dataset.split(0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwSC_5XMGJae"
      },
      "source": [
        "batch_size = 16\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train, test), \n",
        "     batch_size = batch_size,\n",
        "     sort_within_batch = True,\n",
        "     sort_key = lambda x : len(x.context),\n",
        "     device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xgJTSOBL9Y9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "fceb6b82-7cfd-4014-fc59-239f1679b808"
      },
      "source": [
        "print('train len:', len(train.examples))\n",
        "print('test len:', len(test.examples), '\\n')\n",
        "\n",
        "context.build_vocab(train, min_freq = 2)\n",
        "reply.build_vocab(train, min_freq = 2)\n",
        "print(\"Number of words in context\", len(context.vocab))\n",
        "print(\"Number of words in reply\", len(reply.vocab),'\\n')\n",
        "\n",
        "for i in range(10):\n",
        "  print(train[i].context, train[i].reply)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train len: 43716\n",
            "test len: 18736 \n",
            "\n",
            "Number of words in context 9334\n",
            "Number of words in reply 8456 \n",
            "\n",
            "['жиза'] ['ввс', 'перестанет', 'сотрудничать', 'с', 'первым', ',', 'вот', 'так', 'вот']\n",
            "['чо', 'это'] ['чо', 'фасоль', 'фу']\n",
            "['реву'] ['какую', 'книгу']\n",
            "['я', 'удалил', '6', 'гб', 'ненужного', 'хлама', '.'] ['продолжай', 'в', 'том', 'же', 'духе']\n",
            "['латна', '.'] ['.']\n",
            "['што'] ['inj']\n",
            "['то', 'есть', 'седня', 'ты', 'халявничаешь'] ['я', 'читаю']\n",
            "['это', 'што'] ['раксакорикофаллапаториус']\n",
            "['а', 'ты', 'чо', 'тош', 'в', 'школе'] ['тааа']\n",
            "['что', 'делаешь', '?'] ['та', 'чот', 'сижу']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI77odK1g8hq"
      },
      "source": [
        "### movie dialogs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyUZQMNMhCQ6"
      },
      "source": [
        "context = Field(tokenize = 'spacy',\n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n",
        "\n",
        "reply = Field(tokenize = 'spacy',\n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcmYcV6bhFjz"
      },
      "source": [
        "dataset = TabularDataset(movie, 'csv', \n",
        "                          [('context', context), (\"reply\", reply)], \n",
        "                          skip_header=True)\n",
        "\n",
        "train, test = dataset.split(0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nys62rRxhJLt"
      },
      "source": [
        "batch_size = 16\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train, test), \n",
        "     batch_size = batch_size,\n",
        "     sort_within_batch = True,\n",
        "     sort_key = lambda x : len(x.context),\n",
        "     device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xru-9DShMkq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "dc7f030f-ce94-4ef6-a783-f9118964107f"
      },
      "source": [
        "print('train len:', len(train.examples))\n",
        "print('test len:', len(test.examples), '\\n')\n",
        "\n",
        "context.build_vocab(train, min_freq = 5)\n",
        "reply.build_vocab(train, min_freq = 5)\n",
        "print(\"Number of words in context\", len(context.vocab))\n",
        "print(\"Number of words in reply\", len(reply.vocab),'\\n')\n",
        "\n",
        "for i in range(10):\n",
        "  print(train[i].context, train[i].reply)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train len: 42034\n",
            "test len: 18015 \n",
            "\n",
            "Number of words in context 4497\n",
            "Number of words in reply 3443 \n",
            "\n",
            "['я', 'пойму', ',', 'если', 'ты', 'не', 'сообщишь', 'семье', 'прямо', 'сейчас', '.'] ['как', 'ты', 'не', 'поймёшь', ',', 'мы', 'друзья', '.']\n",
            "['правда', '?'] ['конечно', 'правда', '!']\n",
            "['на', 'днище', 'ее', 'машины', 'я', 'нашел', 'gps', '-', 'датчик', 'слежения', '.'] ['по', 'данным', 'твоего', 'gps', 'ты', 'в', 'трех', 'с', 'половиной', 'милях', 'от', 'него', '.']\n",
            "['не', 'убивайте', 'меня', ',', 'пожалуйста', '.'] ['пожалуйста', 'ответь', 'на', 'вопрос', '.']\n",
            "['я', 'знаю', 'кое', '-', 'кого', 'кто', 'тебя', 'подвезет', '.'] ['кого', '?']\n",
            "['нравится', '?'] ['да', ',', 'тебе', 'идёт', '.']\n",
            "['да', ',', 'дождь', '.'] ['не', 'хочу', ',', 'чтобы', 'ты', 'шёл', '.']\n",
            "['ну', ',', 'когда', 'у', 'него', 'есть', 'работа', '.', 'что', 'не', 'так', 'часто', 'в', 'последнее', 'время', '.'] ['я', 'потерял', 'свою', 'работу', '.', '.', '.', '.', 'учитывая', 'некоторые', 'странные', 'обстоятельства', '.']\n",
            "['что', 'ты', 'делаешь', '?'] ['ничего', '.']\n",
            "['воу', '.'] ['вот', 'так', 'дела', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN1dvfWVmrcA"
      },
      "source": [
        "##Seq2seq модель с attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAdTL0b0qanC"
      },
      "source": [
        "Получилось очень плохо! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIIki9KJgIJu"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bias=False)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim, dec_hid_dim, bias=False)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "\n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        #src = [src sent len, batch size]\n",
        "        #src_len = [src sent len]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src sent len, batch size, emb dim]\n",
        "        \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n",
        "        \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "                     \n",
        "        #packed_outputs is a packed sequence containing all hidden states\n",
        "        #hidden is now from the final non-padded element in the batch\n",
        "            \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "            \n",
        "        #outputs is now a non-packed sequence, all hidden states obtained\n",
        "        #  when the input is a pad token are all zeros\n",
        "            \n",
        "        #outputs = [sent len, batch size, hid dim * num directions]\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #outputs are always from the last layer\n",
        "        \n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        #  encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(hidden[-1,:,:]))\n",
        "        \n",
        "        #outputs = [sent len, batch size, enc hid dim * 2]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcHYE3sUnh5x"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        \n",
        "        self.attn = nn.Linear(enc_hid_dim + dec_hid_dim, dec_hid_dim, bias=False)\n",
        "        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        \n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
        "        #mask = [batch size, src sent len]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #repeat encoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #hidden = [batch size, src sent len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        \n",
        "        #energy = [batch size, src sent len, dec hid dim]\n",
        "                \n",
        "        energy = energy.permute(0, 2, 1)\n",
        "        \n",
        "        #energy = [batch size, dec hid dim, src sent len]\n",
        "        \n",
        "        #v = [dec hid dim]\n",
        "        \n",
        "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
        "        \n",
        "        #v = [batch size, 1, dec hid dim]\n",
        "            \n",
        "        attention = torch.bmm(v, energy).squeeze(1)\n",
        "        \n",
        "        #attention = [batch size, src sent len]\n",
        "      \n",
        "        \n",
        "        return F.softmax(attention, dim = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kMw_515nkY_"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(enc_hid_dim + emb_dim, dec_hid_dim)\n",
        "        \n",
        "        self.out = nn.Linear(enc_hid_dim + dec_hid_dim + emb_dim, output_dim, bias=False)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
        "        #mask = [batch size, src sent len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs)\n",
        "                \n",
        "        #a = [batch size, src sent len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a = [batch size, 1, src sent len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        \n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output = [sent len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
        "        \n",
        "        #sent len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, dec hid dim]\n",
        "        #hidden = [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        output = self.out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        #output = [bsz, output dim]\n",
        "        \n",
        "        return output, hidden.squeeze(0), a.squeeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmUtAFtEnmoI"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, pad_idx, sos_idx, eos_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.pad_idx = pad_idx\n",
        "        self.sos_idx = sos_idx\n",
        "        self.eos_idx = eos_idx\n",
        "        self.device = device\n",
        "\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src sent len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        #trg = [trg sent len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "        \n",
        "        if trg is None:\n",
        "            assert teacher_forcing_ratio == 0, \"Must be zero during inference\"\n",
        "            inference = True\n",
        "            trg = torch.zeros((100, src.shape[1])).long().fill_(self.sos_idx).to(src.device)\n",
        "        else:\n",
        "            inference = False\n",
        "            \n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #tensor to store attention\n",
        "        attentions = torch.zeros(max_len, batch_size, src.shape[0]).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        output = trg[0,:]\n",
        "        \n",
        "                \n",
        "        for t in range(1, max_len):\n",
        "            output, hidden, attention = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            attentions[t] = attention\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "            if inference and output.item() == self.eos_idx:\n",
        "                return outputs[:t], attentions[:t]\n",
        "            \n",
        "        return outputs, attentions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "558GeJbino-k"
      },
      "source": [
        "INPUT_DIM = len(context.vocab)\n",
        "OUTPUT_DIM = len(reply.vocab)\n",
        "ENC_EMB_DIM = 150\n",
        "DEC_EMB_DIM = 150\n",
        "ENC_HID_DIM = 100\n",
        "DEC_HID_DIM = 100\n",
        "ENC_DROPOUT = 0.7\n",
        "DEC_DROPOUT = 0.7\n",
        "PAD_IDX = context.vocab.stoi['<pad>']\n",
        "SOS_IDX = reply.vocab.stoi['<sos>']\n",
        "EOS_IDX = reply.vocab.stoi['<eos>']\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, PAD_IDX, SOS_IDX, EOS_IDX, device).to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBQIfkBFntHu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "394a14fe-45c1-434c-8a83-ef7be43ab840"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Модель содержит {count_parameters(model):,} параметров')            \n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Модель содержит 2,606,750 параметров\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(4497, 150)\n",
              "    (rnn): GRU(150, 100, bias=False)\n",
              "    (fc): Linear(in_features=100, out_features=100, bias=False)\n",
              "    (dropout): Dropout(p=0.7, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=200, out_features=100, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(3443, 150)\n",
              "    (rnn): GRU(250, 100)\n",
              "    (out): Linear(in_features=350, out_features=3443, bias=False)\n",
              "    (dropout): Dropout(p=0.7, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK_4S0Hfntnt"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        #src, src_len = batch.src\n",
        "        src = batch.context\n",
        "        src_len_np = np.full((src.shape[1]), src.shape[0])\n",
        "        src_len = torch.tensor(src_len_np)\n",
        "        trg = batch.reply\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, attetion = model(src, src_len, trg, 0.2)\n",
        "        \n",
        "        #trg = [trg sent len, batch size]\n",
        "        #output = [trg sent len, batch size, output dim]\n",
        "        \n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg sent len - 1) * batch size]\n",
        "        #output = [(trg sent len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJtu9C-7nwFJ"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            #src, src_len = batch.src\n",
        "            src = batch.context\n",
        "            src_len_np = np.full((src.shape[1]), src.shape[0])\n",
        "            src_len = torch.tensor(src_len_np)\n",
        "            trg = batch.reply\n",
        "\n",
        "            output, attention = model(src, src_len, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg sent len, batch size]\n",
        "            #output = [trg sent len, batch size, output dim]\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg sent len - 1) * batch size]\n",
        "            #output = [(trg sent len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2A9jQgRnyV0"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHsekZKgn07i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "0f7ec45a-0a6a-423f-a443-76f4a50e604b"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/state dicts/attention0002.pt')\n",
        "    \n",
        "    print(f'Эпоха: {epoch+1:02} | Время: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'Перплексия (обучение): {math.exp(train_loss):7.3f}')\n",
        "    print(f'Перплексия (валидация): {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Эпоха: 01 | Время: 4m 19s\n",
            "Перплексия (обучение):  92.833\n",
            "Перплексия (валидация):  74.676\n",
            "Эпоха: 02 | Время: 4m 20s\n",
            "Перплексия (обучение):  71.441\n",
            "Перплексия (валидация):  67.576\n",
            "Эпоха: 03 | Время: 4m 18s\n",
            "Перплексия (обучение):  63.109\n",
            "Перплексия (валидация):  63.903\n",
            "Эпоха: 04 | Время: 4m 22s\n",
            "Перплексия (обучение):  57.419\n",
            "Перплексия (валидация):  61.712\n",
            "Эпоха: 05 | Время: 4m 19s\n",
            "Перплексия (обучение):  53.085\n",
            "Перплексия (валидация):  61.003\n",
            "Эпоха: 06 | Время: 4m 19s\n",
            "Перплексия (обучение):  49.626\n",
            "Перплексия (валидация):  60.608\n",
            "Эпоха: 07 | Время: 4m 21s\n",
            "Перплексия (обучение):  47.006\n",
            "Перплексия (валидация):  60.765\n",
            "Эпоха: 08 | Время: 4m 21s\n",
            "Перплексия (обучение):  44.795\n",
            "Перплексия (валидация):  60.608\n",
            "Эпоха: 09 | Время: 4m 23s\n",
            "Перплексия (обучение):  42.797\n",
            "Перплексия (валидация):  61.716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-27078f2d4be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-900efb0ed039>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFf6E7iiop2r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8587ddbd-00b0-47c9-ec1a-2b1a508f3f3a"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/My Drive/state dicts/attention0002.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryb-efmHf1If"
      },
      "source": [
        "def answer(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = ['<sos>'] + [t.lower() for t in sentence.split(' ')] + ['<eos>']\n",
        "    numericalized = [context.vocab.stoi[t] for t in tokenized] \n",
        "    sentence_length = torch.LongTensor([len(numericalized)]).to(device) \n",
        "    tensor = torch.LongTensor(numericalized).unsqueeze(1).to(device) \n",
        "\n",
        "    logits, attention = model(tensor, sentence_length, None, 0) \n",
        "    translation_tensor = torch.argmax(logits.squeeze(1), 1)\n",
        "    decoded = [reply.vocab.itos[t] for t in translation_tensor]\n",
        "    decoded, attention = translation[1:], attention[1:]\n",
        "    return decoded, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm1OdASpf5Gz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88232f13-b489-4234-9069-c43fbb0b0fd7"
      },
      "source": [
        "a, _ = answer(model,\"что делаешь?\")\n",
        "print(\" \".join(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "я ,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9IcWkBuhALn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}